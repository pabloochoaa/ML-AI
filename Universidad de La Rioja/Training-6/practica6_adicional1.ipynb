{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA2122/practica-6-paochoa/blob/main/practica6_adicional1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlTVT2TbId5d"
      },
      "source": [
        "# Práctica 6. Ejercicio adicional 1: Preprocesado de datos\n",
        "\n",
        "La calidad de los datos y la cantidad de información relevante que dichos datos contienen son factores clave a la hora de que un algoritmo de aprendizaje sea capaz de aprender. En este notebook se ven distintas técnicas de preprocesado de datos y su impacto a la hora de entrenar modelos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u1P27zGId5h"
      },
      "source": [
        "## 0. Carga de librerías y del dataset \n",
        "\n",
        "Para este notebook vamos a utilizar el dataset del Vino, otro dataset open-source que está disponible en el [repositorio UCI](https://archive.ics.uci.edu/ml/datasets/wine). Este dataset consiste en 178 muestras de vinos y 13 descriptores de distintas propiedades químicas. \n",
        "\n",
        "Usando pandas vamos a descargar directamente dicho dataset. También definimos en la siguiente celda el nombre de las columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "0-mrM8Y3Id5h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q-195y6PId5i"
      },
      "outputs": [],
      "source": [
        "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
        "                     header=None)\n",
        "df_wine.columns = ['Class label', 'Alcohol', 'Malid acid', 'Ash', 'Alcalinity of ash', \n",
        "                  'Magnesium', 'Total phenols','Flavanoids','Nonflavanoid phenols', \n",
        "                  'Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines',\n",
        "                  'Proline']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btCRxLO5Id5j"
      },
      "source": [
        "A continuación podemos ver las categorías de vinos de nuestro dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i_3MvHX9Id5j",
        "outputId": "4727b6e1-f5da-471d-ef12-1bfe83253ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels [1 2 3]\n"
          ]
        }
      ],
      "source": [
        "print('Class labels',np.unique(df_wine['Class label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8aOap48Id5k"
      },
      "source": [
        "##### Pregunta\n",
        "¿Cuántas clases hay?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "J0lk_kWYId5k"
      },
      "source": [
        "Respuesta. \n",
        "\n",
        "Hay 3 clases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z75LUhd2Id5l"
      },
      "source": [
        "**Ejercicio** Muestra las primeras filas del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2bLu6L0TId5l",
        "outputId": "f550c9a6-7c25-45b3-8f3a-4c51840eee45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Class label  Alcohol  Malid acid   Ash  Alcalinity of ash  Magnesium  \\\n",
              "0             1    14.23        1.71  2.43               15.6        127   \n",
              "1             1    13.20        1.78  2.14               11.2        100   \n",
              "2             1    13.16        2.36  2.67               18.6        101   \n",
              "3             1    14.37        1.95  2.50               16.8        113   \n",
              "4             1    13.24        2.59  2.87               21.0        118   \n",
              "..          ...      ...         ...   ...                ...        ...   \n",
              "95            2    12.47        1.52  2.20               19.0        162   \n",
              "96            2    11.81        2.12  2.74               21.5        134   \n",
              "97            2    12.29        1.41  1.98               16.0         85   \n",
              "98            2    12.37        1.07  2.10               18.5         88   \n",
              "99            2    12.29        3.17  2.21               18.0         88   \n",
              "\n",
              "    Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
              "0            2.80        3.06                  0.28             2.29   \n",
              "1            2.65        2.76                  0.26             1.28   \n",
              "2            2.80        3.24                  0.30             2.81   \n",
              "3            3.85        3.49                  0.24             2.18   \n",
              "4            2.80        2.69                  0.39             1.82   \n",
              "..            ...         ...                   ...              ...   \n",
              "95           2.50        2.27                  0.32             3.28   \n",
              "96           1.60        0.99                  0.14             1.56   \n",
              "97           2.55        2.50                  0.29             1.77   \n",
              "98           3.52        3.75                  0.24             1.95   \n",
              "99           2.85        2.99                  0.45             2.81   \n",
              "\n",
              "    Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
              "0              5.64  1.04                          3.92     1065  \n",
              "1              4.38  1.05                          3.40     1050  \n",
              "2              5.68  1.03                          3.17     1185  \n",
              "3              7.80  0.86                          3.45     1480  \n",
              "4              4.32  1.04                          2.93      735  \n",
              "..              ...   ...                           ...      ...  \n",
              "95             2.60  1.16                          2.63      937  \n",
              "96             2.50  0.95                          2.26      625  \n",
              "97             2.90  1.23                          2.74      428  \n",
              "98             4.50  1.04                          2.77      660  \n",
              "99             2.30  1.42                          2.83      406  \n",
              "\n",
              "[100 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e48ceda6-d1d0-4dc6-a648-9a788ac2865e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class label</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malid acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2</td>\n",
              "      <td>12.47</td>\n",
              "      <td>1.52</td>\n",
              "      <td>2.20</td>\n",
              "      <td>19.0</td>\n",
              "      <td>162</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.27</td>\n",
              "      <td>0.32</td>\n",
              "      <td>3.28</td>\n",
              "      <td>2.60</td>\n",
              "      <td>1.16</td>\n",
              "      <td>2.63</td>\n",
              "      <td>937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2</td>\n",
              "      <td>11.81</td>\n",
              "      <td>2.12</td>\n",
              "      <td>2.74</td>\n",
              "      <td>21.5</td>\n",
              "      <td>134</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.56</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.95</td>\n",
              "      <td>2.26</td>\n",
              "      <td>625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2</td>\n",
              "      <td>12.29</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.98</td>\n",
              "      <td>16.0</td>\n",
              "      <td>85</td>\n",
              "      <td>2.55</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2.74</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2</td>\n",
              "      <td>12.37</td>\n",
              "      <td>1.07</td>\n",
              "      <td>2.10</td>\n",
              "      <td>18.5</td>\n",
              "      <td>88</td>\n",
              "      <td>3.52</td>\n",
              "      <td>3.75</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.95</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.77</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2</td>\n",
              "      <td>12.29</td>\n",
              "      <td>3.17</td>\n",
              "      <td>2.21</td>\n",
              "      <td>18.0</td>\n",
              "      <td>88</td>\n",
              "      <td>2.85</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.45</td>\n",
              "      <td>2.81</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1.42</td>\n",
              "      <td>2.83</td>\n",
              "      <td>406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e48ceda6-d1d0-4dc6-a648-9a788ac2865e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e48ceda6-d1d0-4dc6-a648-9a788ac2865e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e48ceda6-d1d0-4dc6-a648-9a788ac2865e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_wine.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYVj7YJnId5m"
      },
      "source": [
        "##### Ejercicio\n",
        "La variable `df_wine` contiene tanto las etiquetas como los descriptores, separa dicha variable en las variables `X` e `y` como hemos hecho en otras ocasiones. Date cuenta que en este caso la etiqueta no la proporciona la última columna sino la primera, y que los descriptores van desde la columna 1 hasta la última. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "WqWBEdyVId5m"
      },
      "outputs": [],
      "source": [
        "X = df_wine.values[:,1:] # si se pone esto con iloc se devuelve un dataframe, por lo que no se puede hacer X[0], sin embargo, values devuelve un vector\n",
        "y = df_wine.values[:,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FDA_BwsId5m"
      },
      "source": [
        "La siguiente celda debería producir los siguientes resultados:\n",
        "\n",
        "| Expresión | Resultado |\n",
        "|---|---|\n",
        "| X[0] | [  1.42300000e+01,1.71000000e+00,2.43000000e+00,1.56000000e+01,1.27000000e+02,2.80000000e+00   3.06000000e+00,2.80000000e-01,2.29000000e+00,5.64000000e+00, 1.04000000e+00,3.92000000e+00,1.06500000e+03] |\n",
        "| y[5] | 1.0 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "O_HyrrmIId5n",
        "outputId": "e6a549d6-f845-4b7e-94c3-f9f1c290816e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(X[0])\n",
        "print(y[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOjOsBM-Id5n"
      },
      "source": [
        "##### Ejercicio\n",
        "Como hacemos de manera habitual vamos a partir el dataset en los conjuntos de entrenamiento y test. Utiliza el 30% para el conjunto de test y usa como `random_state` el valor 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "7DSJZTeyId5n"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf9sVYBMId5o"
      },
      "source": [
        "## 1. Escalando los descriptores\n",
        "\n",
        "El escalado de los descriptores es un paso habitual de preprocesamiento. La mayoría de algoritmos de aprendizaje aprenden mucho mejor cuando los descriptores están en la misma escala. \n",
        "\n",
        "La importancia de escalar los descriptores se puede ilustrar con el siguiente ejemplo. Suponed que tenemos dos descriptores donde un descriptor se mide en una escala de 1 a 10 y otra se mide en una escala 1 a 100000. Cuando pensamos en el error cuadrático, es intuitivo que los algoritmos de optimización ajustarán los pesos de acuerdo a los errores producidos en el segundo descriptor. Otro ejemplo sería en el algoritmo KNN con la medida Euclídea, donde el cálculo de las distancias va a estar dominado por el segundo descriptor.\n",
        "\n",
        "Existen dos aproximaciones distintas para escalar los descriptores: la normalización y la estandarización.\n",
        "\n",
        "### 1.1. Normalización\n",
        "\n",
        "La normalización se refiere al proceso de reescalar los descriptores en el rango $[0,1]$. Para llevar a cabo este reescalado se puede aplicar el escalado min-max a cada columna de un descriptor. En concreto para calcular este valor usamos la siguiente fórmula:\n",
        "$$x_{norm}^{(i)} = \\frac{x^{(i)}-x_{min}}{x_{max}-x_{min}}$$\n",
        "donde $x_{norm}^{(i)}$ es el nuevo valor de la instancia $i$ del dataset para un descriptor, $x^{(i)}$ es el valor original de la instancia para ese descriptor, $x_{min}$ es el menor valor que toma ese descriptor para todas las instancias del dataset, y $x_{max}$ es el mayor valor que toma ese descriptor para todas las instancias del dataset.\n",
        "\n",
        "Este procedimiento está implementado en sklearn y puede usarse del siguiente modo. Importamos la librería y definimos un objeto de la clase `MinMaxScaler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "mxFjwkicId5o"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPAspq--Id5p"
      },
      "source": [
        "Llevamos a cabo el reescalado tanto del conjunto de entrenamiento utilizando la función `fit_transform` del objeto `mms`, y luego reescalamos el conjunto de test utilizando la función `transform`. Esto se hace para que el reescalado del conjunto de test utilice los mismos valores de reescalado que el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LUj1ZysXId5p"
      },
      "outputs": [],
      "source": [
        "# se hace así y no normalizando X porque sino se cogería infor del conjunto de test para el de entrenamiento\n",
        "# Por ejemplo si el de test tuviese un máximo, al normalizar X se normalizaría usando ese valor\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri6Eh6d6Id5p"
      },
      "source": [
        "### 1.2. Estandarización\n",
        "\n",
        "La normalización es una técnica útil cuando necesitamos que los nuevos valores de los descriptores estén en un intervalo, la estandarización puede ser más útil para los algoritmos de aprendizaje. La razón es que muchos algoritmos como la regresión logística, SVMs o las redes neuronales inicializan los pesos a 0 o a valores aleatoreos cercanos a 0. Usando la estandarización se consiguen centrar las columnas de descriptores con media 0 y desviación típica 1 de modo que las columnas de descriptores toman la forma de una distribución normal lo que hace que se aprendan de manera más sencilla los pesos. \n",
        "\n",
        "El proceso de estandarización viene dado por la siguiente fórmula:\n",
        "$$x^{(i)}_{std} = \\frac{x^{(i)}-\\mu_x}{\\sigma_x}$$\n",
        "donde $\\mu_x$ es la media de la muestra para cada columna de descriptores, $\\sigma_x$ es la desviación típica, y $x^{(i)}_{std}$ es el valor calculado a partir del original $x^{(i)}$.\n",
        "\n",
        "La siguiente tabla muestra la diferencia entre los valores normalizados y estandarizados en un dataset que contiene los números del 0 al 5. \n",
        "\n",
        "| Entrada | Estandarizado | Normalizado |\n",
        "| --- | --- | --- |\n",
        "| 0.0 | -1.33 | 0.0 |\n",
        "| 1.0 | -0.8 | 0.2 |\n",
        "| 2.0 | -0.26 | 0.4 |\n",
        "| 3.0 | 0.26 | 0.6 |\n",
        "| 4.0 | 0.8 | 0.8 |\n",
        "| 5.0 | 1.33 | 1.0 |\n",
        "\n",
        "Al igual que para la normalización, sklearn también implementa la estandarización y se utiliza del mismo modo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "7mu4xPJjId5p"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "stdsc = StandardScaler()\n",
        "X_train_std = stdsc.fit_transform(X_train)\n",
        "X_test_std = stdsc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PXSxEHUId5q"
      },
      "source": [
        "## 2. Seleccionando descriptores relevantes\n",
        "\n",
        "Cuando un modelo funciona mucho mejor en el conjunto de entrenamiento que en el de test, estos es un claro caso de _sobreajuste_. Es decir, que el modelo ha ajustado sus parámetros para funcionar bien en el conjunto de entrenamiento pero no generaliza bien a datos reales. Existen distintas técnicas para reducir el sobreajuste, la más sencilla pero también más complicada de llevar a cabo consiste en conseguir más datos para entrenar el modelo; esto en muchas ocasiones no es posible. En este apartado vamos a ver otra técnica que reduce el sobreajuste utilizando la reducción de dimensionalidad. \n",
        "\n",
        "Ya vimos que existen dos tipos de técnicas para reducir la dimensionalidad: la selección de descriptores y la extracción de descriptores. En este apartado nos vamos a centrar en el uso del método de selección secuencial hacia atrás. Este algoritmo no está implementado por defecto en sklearn, pero lo tienes disponible en el fichero sbs.py. Vamos a ver como funciona nuestro selector de descriptores utilizando el clasificador KNN. Comentamos cargando las librerías necesarias. \n",
        "\n",
        "Necesitamos primero descargar el fichero sbs con la funcionalidad necesaria. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KRApuricId5q",
        "outputId": "bc44ceaa-0e4c-4615-c9d2-b2c8956e720f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-06 14:27:04--  https://raw.githubusercontent.com/IA1819/Code/master/sbs1.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1691 (1.7K) [text/plain]\n",
            "Saving to: ‘sbs.py’\n",
            "\n",
            "sbs.py              100%[===================>]   1.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-06 14:27:04 (13.0 MB/s) - ‘sbs.py’ saved [1691/1691]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/IA1819/Code/master/sbs1.py -O sbs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "id": "u_-ULtA0Id5q"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sbs import SBS\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHqNvf2nId5q"
      },
      "source": [
        "Construimos el clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "id": "JcMnIH9CId5q"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FltdR4nnId5r"
      },
      "source": [
        "Construimos nuestro selector de descriptores y le indicamos que al menos tiene que tomar 1 descriptor. El proceso consiste en construir una instancia de la clase `SBS` donde le indicamos el clasificador y el mínimo número de descriptores, y luego entrenarla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pBU5FTUkId5r",
        "outputId": "b7894ee6-1a4c-468f-bec5-f0a8ac1375c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sbs.SBS at 0x7fe5e0dcd2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sbs= SBS(knn,k_features=1)\n",
        "sbs.fit(X_train_std,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6r0Be_5Id5r"
      },
      "source": [
        "El objeto de la clase sbs almacena las puntuaciones de los mejores subconjuntos de descriptores en cada paso utilizando una parte del conjunto de test como conjunto de validación, así que podemos mostrar la precisión del clasificador para los distintos subconjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7o2kYbaFId5r",
        "outputId": "8ed375b6-c73b-4a7d-9d96-7259b0622950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "k_feat = [len(k) for k in sbs.subsets_]\n",
        "plt.plot(k_feat,sbs.scores_,marker='o')\n",
        "plt.ylim([0.7,1.1])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Numero descriptores')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh3WF5WTId5r"
      },
      "source": [
        "Como se puede ver en la figura anterior la accuracy del algoritmo KNN aumenta al reducir el número de descriptores lo cual se debe a la maldición de la dimensionalidad. Como se puede ver en la gráfica, el algoritmo KNN alcanza una accuracy del 100% utilizando entre 5 y 11 descriptores. \n",
        "\n",
        "Podemos tomar los 5 descriptores más relevantes y ver cuáles son. Como estamos utilizando la eliminación hacia atrás para acceder a los 5 descriptores más relevantes tenemos que acceder al campo `subsets_` (que es una lista) e indicarle el índice que sería 13 (número total de descriptores) - 5 (número de descriptores con los que nos quedamos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "S_Z2qseeId5r",
        "outputId": "482a9430-f201-4c67-f508-0ae932f7a747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Malid acid', 'Total phenols', 'Flavanoids', 'Color intensity',\n",
            "       'Proline'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "k5 = list(sbs.subsets_[8]) \n",
        "print(df_wine.columns[1:][k5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0btaqB4-Id5s"
      },
      "source": [
        "Vamos ahora a evaluar el rendimiento del clasificador KNN en el conjunto de test. Primero lo consideramos sin estandarizar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nVTmgrtoId5s",
        "outputId": "faaebd65-9a3e-48ec-c9f4-a35ed14e88c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9032258064516129\n",
            "Test accuracy: 0.7037037037037037\n"
          ]
        }
      ],
      "source": [
        "knn.fit(X_train,y_train)\n",
        "print('Training accuracy:', knn.score(X_train,y_train)) # aquí hay un claro ejemplo de sobreajuste, ya que la diferencia de precisión en ambos conjuntos en mayor de 20 puntos.\n",
        "print('Test accuracy:', knn.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS4xZKVdId5s"
      },
      "source": [
        "A continuación utilizando el dataset normalizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UXLPQAm_Id5s",
        "outputId": "304c19d7-cf40-4c41-d05b-88479d1dc63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.967741935483871\n",
            "Test accuracy: 0.9814814814814815\n"
          ]
        }
      ],
      "source": [
        "knn.fit(X_train_norm,y_train)\n",
        "print('Training accuracy:', knn.score(X_train_norm,y_train))\n",
        "print('Test accuracy:', knn.score(X_test_norm,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiDy5RmSId5s"
      },
      "source": [
        "A continuación utilizando el dataset estandarizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IylDHmqQId5s",
        "outputId": "3ce7e6a0-15bc-4b1d-cb76-1865b4c6998c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9596774193548387\n",
            "Test accuracy: 0.9629629629629629\n"
          ]
        }
      ],
      "source": [
        "knn.fit(X_train_std,y_train)\n",
        "print('Training accuracy:', knn.score(X_train_std,y_train))\n",
        "print('Test accuracy:', knn.score(X_test_std,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THy12vwNId5s"
      },
      "source": [
        "Por último considerando solo los 5 descriptores más relevantes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GBgViEJQId5t",
        "outputId": "145b7526-1538-4708-c041-10b3a8ae83d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9758064516129032\n",
            "Test accuracy: 0.9629629629629629\n"
          ]
        }
      ],
      "source": [
        "knn.fit(X_train_std[:,k5],y_train)\n",
        "print('Training accuracy:', knn.score(X_train_std[:,k5],y_train))\n",
        "print('Test accuracy:', knn.score(X_test_std[:,k5],y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0A0BB37Id5t"
      },
      "source": [
        "##### Pregunta\n",
        "¿Qué ha ocurrido al estandarizar los datos? ¿y al normalizarlos? ¿Ha mejorado la accuracy de nuestro clasificador? ¿Qué ha ocurrido al utilizar los 5 descriptores más importantes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "WKONbE3WId5t"
      },
      "source": [
        "Respuesta. \n",
        "\n",
        "Al estandarizar los datos la precisión ha subido más que al normalizarlos. Al eliminar los descriptores y quedarnos solo con 5, ha mejorado todavía más la precisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqY5J0-SId5t"
      },
      "source": [
        "**Ejercicio** En la selección de descriptores anterior, hemos considerado el dataset estandarizado para elegir los 5 mejores descriptores. Repite el proceso, pero esta vez condiderando el dataset original. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OZhzf-s5Id5t",
        "outputId": "805c6d89-bfda-46dc-e74e-ce9ee34dfe07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.8709677419354839\n",
            "Test accuracy: 0.7777777777777778\n"
          ]
        }
      ],
      "source": [
        "knn.fit(X_train[:,k5],y_train)\n",
        "print('Training accuracy:', knn.score(X_train[:,k5],y_train)) # aquí sigue habiendo un sobreajuste, pero este es menor que el que teníamos inicialmente\n",
        "print('Test accuracy:', knn.score(X_test[:,k5],y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDhkzO5OId5t"
      },
      "source": [
        "**Pregunta** \n",
        "\n",
        "¿Mejoran los resultados con respecto al entrenamiento del modelo con todos los descriptores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyiW9BjZId5t"
      },
      "source": [
        "Respuesta.\n",
        "\n",
        "La precisión de entrenamiento baja un poco, pero la de testeo aumenta un poco más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9eW0kzoId5t"
      },
      "source": [
        "## 3. Viendo la importancia de los descriptores \n",
        "\n",
        "Una técnica que también resulta útil para seleccionar descriptores relevantes a partir de un dataset consiste en utilizar [_random forests_](http://scikit-learn.org/stable/modules/ensemble.html#forest) un método en el cual se entrenan varios árboles de decisión y se organiza una votación entre esos modelos para decidir la predicción.\n",
        "\n",
        "Utilizando los random forest podemos ver la importancia de cada descriptor usando el atributo `feature_importances_` que está accesible después de entrenar uno de estos clasificadores. Ejecutando el siguiente código se entrenará uno de estos modelos utilizando 1000 árboles de decisión y se obtendrá un ranking de los 13 descriptores. \n",
        "\n",
        "Comenzamos cargando las libreráis necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "_SrB90hbId5u"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SJPlcfvId5u"
      },
      "source": [
        "Obtenemos el nombre de cada descriptor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "7z1dB6-DId5u"
      },
      "outputs": [],
      "source": [
        "etiquetas_descriptores = df_wine.columns[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB8binMTId5u"
      },
      "source": [
        "Construimos el _random forest_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "id": "7M8hebcqId5u"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators=1000,random_state=0,n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGIUUh0ZId5u"
      },
      "source": [
        "Entrenamos el modelo. Notar que usamos directamente el dataset sin estandarizar, esto es debido a que los árboles de decisión no están afectados por la escala de los atributos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4jBT68e2Id5u",
        "outputId": "00cd75b0-81a9-4c0f-aa22-8d908a6f4876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "forest.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPfuspzVId5v"
      },
      "source": [
        "Obtenemos la relevancia de cada descriptor y los índices para ordenar de mayor a menor dichas relevancias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "id": "hgFFXf7QId5v"
      },
      "outputs": [],
      "source": [
        "relevancias = forest.feature_importances_\n",
        "indices = np.argsort(relevancias)[::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNKElQUBId5v"
      },
      "source": [
        "Por último mostramos la importancia de cada descriptor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "a8_NTWxrId5v",
        "outputId": "d1e178db-bbe5-4494-de30-a5f7713c7358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1) Color intensity                0.190583\n",
            " 2) Proline                        0.159246\n",
            " 3) Flavanoids                     0.149066\n",
            " 4) OD280/OD315 of diluted wines   0.137214\n",
            " 5) Alcohol                        0.103509\n",
            " 6) Hue                            0.071931\n",
            " 7) Total phenols                  0.059530\n",
            " 8) Alcalinity of ash              0.032480\n",
            " 9) Malid acid                     0.023645\n",
            "10) Magnesium                      0.022201\n",
            "11) Proanthocyanins                0.021967\n",
            "12) Nonflavanoid phenols           0.015877\n",
            "13) Ash                            0.012752\n"
          ]
        }
      ],
      "source": [
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%2d) %-*s %f\" % (f+1,30,etiquetas_descriptores[indices[f]],relevancias[indices[f]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht3_Sma9Id5v"
      },
      "source": [
        "##### Pregunta\n",
        "¿Cuál es el descriptor más relevante?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "6wWTJm_hId5v"
      },
      "source": [
        "Respuesta. \n",
        "\n",
        "La intensidad del color es el descriptor más importante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZlot-yKId5v"
      },
      "source": [
        "Vamos a mostrar un gráfico con la relevancia de cada descriptor. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Gnxd5pllId5v",
        "outputId": "c5397955-02b6-4f5f-a831-23779f95f093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEYCAYAAABoYED3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gkVbnH8e+PJS8sQREkCEgOSlpEJStIUIIgIEEFUQEVUcR8RUCvAYwXFUEQCQosQUAlSA4i4i55CYqABEFBclBkee8f5/RMTW9P2J2q6uma3+d55pnuqu5+T0/X9Ft1oiICMzOzqs3R7QKYmdn44IRjZma1cMIxM7NaOOGYmVktnHDMzKwWTjhmZlYLJxybLZKulPShbpejE0kbS7q7pNfaTNJDs/ncn0v6WhnlGCLGYZJOrTJGh5jTJW1WZ0xrBieccUzS/ZJelPScpEfzF+QC3S7XaEXENRGxSrfL0VQRsUZEXDmSx+ZjbIuKi2Q9wgnHtouIBYC1gXWAL3S5PDZGSZqzyfGsek44BkBEPApcTEo8AEh6s6TrJD0l6ZahqlEkfVDSnZKelHSxpGXz9mMkfbvtsedJOjjf/rykv0p6VtIdkt5deNzekq6V9O38uvdJ2qawf1FJJ0r6e95/bt4+oBpsqBgd3sd8+UrvSUl3AOu37V9S0tmSHsvl+cRwf9vCcz8s6R5JT0g6X9KSebskfU/SPyU9I+k2SWsO8hrLS7oqv5dLgFe37R/0M8t/z3vzc++TtGdb2e4s/I3Wzdvvl/Q5SbcCz0uas3jVkqv0zpJ0Rn7ujZLWyvtOAV4H/DpfRX82b98+V8s9latmVyuUo1O82XpPNgZFhH/G6Q9wP7BFvr00cBvwg3x/KeBfwLakE5Mt8/3F8v4rgQ/l2zsA9wCrAXMC/wNcl/dtAjwIKN9fBHgRWDLf3wVYMsfYDXgeeG3etzfwX+DDwATgAODvhdf6LXBGfs25gE3z9s2Ahwrvc9AYHf4m3wSuARYFlgFub71Wfv404FBgbuD1wL3AVoO81s+Br+XbbwMeB9YF5gGOBq7O+7bKr7swoPx3HKx8fwC+m19jE+BZ4NThPjNgIvAMsEp+7GuBNQp/n4dJyVXAisCyhWPk5vy3mK/DcXNY/ozekz+DQ4D7gLnaH5vvr5z//lvmx3+WdOzM3Sne7L4n/4zNn64XwD9d/PDTP/dz+UsrgMuAhfO+zwGntD3+YuAD+faV9CecC4F9C4+bA3gBWDZ/gT0AbJL3fRi4fIgy3QzskG/vDdxT2Dd/LucS+cvlFWCRDq+xGYWEM1SMDvvuBbYu3P8I/QlnA+CBtsd/AThxkNf6Of0J5wTgyMK+BfIX9XKkZPRn4M3AHEOU+3XAy8DEwrZf0p9wBv3M8pfzU8DO5MTR9piDhjhGPthhWzHhXN/22T8CbNz+2Hz/y8CUtsc/DGzWKd7svif/jM0fV6nZjhGxIOlLelX6q2iWBXbJ1RhPSXoK2Ij0Rd9uWeAHhcc9QUo0S0X6hjgd2D0/dg/gF60nSnq/pJsLz12TgdVEj7ZuRMQL+eYCpDPgJyLiyeHe4AhiFC1JuiJr+Vvb+1yy7W/yRWDx4cqQX7fvtSLiOdKZ+lIRcTnwQ+BHwD8lHSdp0iCv8WREPD9E+Tp+Zvk5uwH7A49I+q2kVfPzlgH+OkTZHxxi34D9EfEK8FAuayftf4dX8vOXGiTe7L4nG4OccAyAiLiKdEbeam95kHRmuXDhZ2JEfLPD0x8E9mt77HwRcV3efxrwHqV2nQ2AswHy/Z8CHwdeFRELk6qwNIIiPwgsKmnhoR40GzEeIX0Bt7yuLeZ9be9zwYjYdgTl/Tvpy7NVronAq0hn90TE/0XEesDqpGqnzwxStkXycwcr36CfWURcHBFbkk4a7iL9XVrPW2GIsg83pXzf30vSHKTq2b8P8tz2v4Py8x8eJN7svicbg5xwrOj7wJa50fdUYDtJW0maIGne3Bi/dIfn/QT4gqQ1ACQtJGmX1s6IuInUfnE8cHFEPJV3TSR9uTyWn7cP6epjWBHxCKkq78eSFpE0l6RNOjx0VmNMye9lkfxeDyzsuwF4Njdqz5f/LmtKWr/zSw1wGrCPpLUlzQN8HfhjRNwvaX1JG0iai9S+8W9SdWH7e/4bMBU4XNLckjYCtis8ZNDPTNLiknbIyeo/pKrUVozjgUMkradkxZyoR2o9STsp9Sr7ZH796/O+f5DaulqmAO+U9Pb8fj+dH38dnc3ue7IxyAnH+kTEY8DJwKER8SCpM8AXSV/WD5LOumc6ZiLiV8C3gNMlPUO6gtim7WG/BLbIv1vPuwP4Dqkh/B/AG4Dfz0KR30dqB7kL+Cfpy669bLMa43BSlc99wO+AUwqvNQN4F6kn3330J9GFhitoRFxKar84m3SlsgLw3rx7EunM/Mkc+1/AUYO81B6kq8QngK+QPq9WjKE+szmAg0lXGE8Am5I6YRARZwL/S/psngXOJXWaGKnzSFVbT5I+k50i4r953zeA/8nVYYdExN3AXqROE4+TEuZ2EfFSpxee3fdkY1Ort4+Z2SyTdBiwYkTs1e2y2NjnKxwzM6vFiBKOpK0l3a00aO3zHfYfrDRY7FZJl81i/a+ZmY0Dw1apSZpAGiOwJam745+A3XPdeOsxm5MaQF+QdACpT/1u1RXbzMx6zUiucN5EGnx3b27YO53UiNcnIq4ojJG4ntQt0szMrM9IJsdbioEDsR4i9ZIZzL6k7qozkfQR0shtJk6cuN6qq3qMlplZk0ybNu3xiFis075SZ2OVtBcwmdQ9cSYRcRxwHMDkyZNj6tSpZYY3M7Muk/S3wfaNJOE8zMCR10szcFRwK8gWwJdIEyj+Z1YLaWZmzTaSNpw/ASspTYs+N2mw2vnFB0haBzgW2D4i/ll+Mc3MrNcNm3Ai4mXSPFQXA3eSZnqdLukISdvnhx1FmlDxzDxJ4vmDvJyZmY1TI2rDiYgLgAvath1auF37ErLn3P1IJa+70yqdJkM2M7PR8kwDZmZWCyccMzOrhROOmZnVwgnHzMxq4YRjZma1cMIxM7NaOOGYmVktnHDMzKwWTjhmZlYLJxwzM6uFE46ZmdXCCcfMzGpR6gJsTVXFRKGeJNTMxhtf4ZiZWS2ccMzMrBZOOGZmVgsnHDMzq4U7DYwx7qBgZk3lKxwzM6uFE46ZmdXCCcfMzGrhhGNmZrVwp4FxqorOCeAOCmY2OF/hmJlZLZxwzMysFk44ZmZWCyccMzOrhROOmZnVwgnHzMxq4YRjZma1cMIxM7NaOOGYmVktnHDMzKwWTjhmZlYLJxwzM6vFiBKOpK0l3S3pHkmf77B/E0k3SnpZ0nvKL6aZmfW6YROOpAnAj4BtgNWB3SWt3vawB4C9gV+WXUAzM2uGkSxP8Cbgnoi4F0DS6cAOwB2tB0TE/XnfKxWU0Xqcl0IwMxhZldpSwIOF+w/lbWZmZiNWa6cBSR+RNFXS1Mcee6zO0GZm1mUjSTgPA8sU7i+dt82yiDguIiZHxOTFFltsdl7CzMx61EgSzp+AlSQtL2lu4L3A+dUWy8zMmmbYhBMRLwMfBy4G7gSmRMR0SUdI2h5A0vqSHgJ2AY6VNL3KQpuZWe8ZSS81IuIC4IK2bYcWbv+JVNVmZmbWkWcaMDOzWjjhmJlZLZxwzMysFk44ZmZWCyccMzOrhROOmZnVwgnHzMxqMaJxOGa9ooqZqT0rtVk5fIVjZma1cMIxM7NaOOGYmVktnHDMzKwWTjhmZlYL91Izm03uEWc2a3yFY2ZmtXDCMTOzWjjhmJlZLZxwzMysFk44ZmZWCyccMzOrhROOmZnVwgnHzMxq4YRjZma1cMIxM7NaOOGYmVktPJeaWQ/wvG3WBL7CMTOzWjjhmJlZLVylZmZ9qqi6A1ffWeKEY2ZdUWe7lNvAxgZXqZmZWS2ccMzMrBauUjMzK5Gr7wbnhGNm1oN6sYOHq9TMzKwWTjhmZlaLESUcSVtLulvSPZI+32H/PJLOyPv/KGm5sgtqZma9bdiEI2kC8CNgG2B1YHdJq7c9bF/gyYhYEfge8K2yC2pmZr1tJFc4bwLuiYh7I+Il4HRgh7bH7ACclG+fBbxdksorppmZ9bqR9FJbCniwcP8hYIPBHhMRL0t6GngV8HjxQZI+Anwk331O0t2zU+jZ8Or2sjQgVhPfU1NjNfE9OVbvxKk71rKD7ai1W3REHAccV2dMAElTI2Jyk2I18T01NVYT35Nj9U6cumMNZSRVag8DyxTuL523dXyMpDmBhYB/lVFAMzNrhpEknD8BK0laXtLcwHuB89secz7wgXz7PcDlERHlFdPMzHrdsFVquU3m48DFwATgZxExXdIRwNSIOB84AThF0j3AE6SkNJbUWY1XV6wmvqemxmrie3Ks3olTd6xByRciZmZWB880YGZmtXDCMTOzWjQy4Uh6VbfLYGZmAzUy4QDXSzpT0rZNnfFA0hySJlX02hMlzZFvryxpe0lzVRGriSQdKWmSpLkkXSbpMUl7VRRrQ0mXSPqzpHsl3Sfp3ipi2ejUeVyMVY3sNJCTzBbAB4H1gSnAzyPizxXG3AhYKSJOlLQYsEBE3FdyjF8C+wMzSN3VJwE/iIijSo4zDdgYWAT4fY71UkTsWWKMo4FBD76I+ERZsTrErvSzknRzRKwt6d3Au4CDgasjYq2yYhRi3QV8CphGOi4AiIjSxsFJepahP6uqTnzeBXyVNHJ9TkApXPnxJE0EXoyIVyStDKwKXBgR/y0xRp3HxWLAh4HlKPRGjogPlh1rVjRyAbY8BugS4BJJmwOnAh+VdAvw+Yj4Q5nxJH0FmAysApwIzJVjblhmHGD1iHhG0p7AhcDnSV80pSYc0onIC5L2BX4cEUdKurnkGFNLfr0Rqemzav1fvRM4MyKervBC++mIuLCqFweIiAUBJH0VeAQ4hfTlvydQ5VKU3wd2Am6rYVzf1cDGkhYBfkc6ydqN9B7LUudxcR5wDXAphRORbmtkwsltOHsB7wP+ARxIGpy6NnAmsHzJId8NrAPcCBARf5e0YMkxAObKVVs7Aj+MiP9KquIfUZLeQvpn2zdvm1BmgIg4qXhf0gJ5+3Nlxumgjs/qN/nK40XggHy2+e8yA0haN9+8QtJRwDnAf1r7I+LGMuNl27edjR+TT+IOrSAWpPkZb69pEHkdJ1mVHxcF80fE5yp67dnWyIQD/IF0FrZjRDxU2D5V0k8qiPdSRETryz9fnlfhWOB+4BbgaknLAs9UEOeTwBeAX+VBvq8HrqggDpLWJH1Wi6a7egx4f0RMryIeNXxWEfF5SUeSrj5mSHqemWdYH63vtN0vzpMVwNtKjgfwfL66Pj3H2B14voI4LZ8FLpB0FQOT6XcriFXHSVYdx0XLbyRtGxEXVPT6s6WpbTi7RsSUtm27RMSZFcU7BFgJ2BL4Bqnt6JcRcXQV8dpizxkRL1f02vNHxAtVvHYhxnXAlyLiinx/M+DrEfHWiuJV9llJ2mmo/RFxzmhjdJPSwoo/IFU/Bql975MRcX9F8X4HPAfcBrzS2h4Rh1cQaxPgEOD3EfGtfJL1yTLaEus8LgrtbQImkhL1f6mw/WtWNDXh3BgR6w63reSYWwLvIH2wF0fEJSW+9sFD7S/7jC+f6Z1Aakx/naS1gP0i4qNlxsmxbmlvNO20reSYlXxWkk4cYndU0WAr6SBSW9SzwE+BdUntlL8rO1bdJN0eEWt2uxyj1Y3jYqxqVMKRtA2wLbArcEZh1yRSg/ubulKwUcoN3ZAautenf/LU7YAbIqLUrpWS/kiahPX8iFgnb6vkn1/Sr0jtKafkTXsB60XEu8uO1USt5CxpK1IPxv8BTinz5ErSZ3ObRseehVX1KMzVT5fWkTxzz7RDmLlXVxVVk5WTtCFwc0Q8n7terwt8PyIe6Ga5mtaG83dS76ftSb23Wp4ldR2tRL5k/hbwGtJZc6mXr60qBElXA+tGxLP5/mHAb8uI0SHmg209aKrq6fJB4HBSozeknjWVnfG1dfGdm9RL7fkyqxokLQR8Bdgkb7oKOCIini4rRjFc/r0tcHJucyu769Od+XfdPQsPAA6RVEe10JnAT4DjqehYr/m4OAZYK9dOfJr0vk4BNq0g1og1KuFExC3ALZJ+UVW7xiCOBLaLiDuHfeToLA68VLj/Ut5WtgclvRWI3CvuIPq/dEoVEU8ClY256RCvr0da/mLeAXhzyWF+BtxOutKG1FvyRFIX37JNy20dywNfyD3uXhnmObMkIn6df5803GNLjltFT8/BvBwRx1Qco87j4uXcOWYHUo/WE3IPvK5qWpXalIjYVdJtDLz0b50ZvbGiuL+PiLLH3HSK8yXSwfqrvGlH4IyI+EbJcV5NahzegvS3+x1wUJmDCQuxul6VIemmVtVhSa93c0SsPdy2kmLNQeruf29EPJWHBCwVEbdWEOsSYJeIeCrfXwQ4PSK2KjtWfv1NOm2PiKsriHUY8E/S/1axR9wTJcao87i4CriIVFuwMem93VzVd+BINeoKh3QmDmkUb52mSjoDOJeBB2upvZIi4n8lXUg6gAD2iYibyoyR4zxOuQPehlJ5VUZRW4+hOUjdicseC/GipI0i4tocc0PS2IvSRRoZfx+wsqR5q4hRsFgr2eTYT0p6TYXxPlO4PS/wJlJVeRUnI60FJIsxA3h9iTFqOy5Ig1b3IH1HPJqTd1XDNUasUQknIh7JNx+nwzQVFYaeBLxA6vnUVxz62yVGRdKkSDMMLEoah3N/Yd+iZZ6F5desc1qMOqoyirYrxib9LcseC7E/cHKusxdpUcK9S44BgKQPkU60lgZuJlUP/oFqvpRnSHpdq+E5jwOrrIokIoqfFZKWIc0+UEWssgeDd1LbcZGTzBXAHpJOBe6jor/drGhUlVqLapgLrE6SfhMR78pnsq0+9i0REWWehbXGxlzDzPNznV1ijEXzzU9QcVVGtyhPrhoRVQzObcW4jdRz8fpI83StShrHVHq7gKStSStHXkU6BjcGPhIRF5cda5D4AqZHxOolvubbIuLywcbKVDF2qsrjIp9g755/Hif11j0kIpYtO9bsaNQVTkEd01TU1l00It6Vf9dxFgb1TIsxjYHJs8qqjFonC5U0D7Az+Qqx1WksIo4oK0bBvyPi35KQNE9E3CVplQriEBEXKU2p0+pk8clc/VqJts+s1VZV9pQ9mwKXM/DKt6W0Wgqo7bi4i3Sy+K6IuCfHrayH7qxqbMJRxdNUZLV3F5W0Pf3dKq+MiN9UEKbyaTFqTJ4txc/ocFL31KqcBzxNSqr/Geaxo/WQpIVJ7YeXSHoS+FuF8WaQrkjnBVaXVEkjflb8zF4GTouI35cZICK+kn/vU+brDqKO42In4L2kOfYuIk1DNGaWaGlqlVpl01R0k6RvkqpPfpE37Q78KSK+WHKcZ6lpWozc7foACkkUODZKnBa+Q8xSe6V1eP2ujJCXtCmwEHBRRLw03ONn4/U7thf16uDIovarj9b2Mq8+6jwulOYI3IH0HfE24GTS3IhdnYGikQmnLpJ+zdDVNNuXHO9WYO2IeCXfnwDc1O2ujqMh6XjS4MvWGI/3ATMi4kMVxqx6mqPjgKMj4raqYnRDXe1F3RjekK8GWlcfxXbL9klSRxOjK8dF7r6+C7BbRLy9ztjtGlmlVuPYjm+X/HojsTCpdwuks9nSSFo1twF0/DKOaqa8Xz8Gzpt2udKU971sI2Dv3MnjP1Q8DqxGdbUXdWN4w9IRsXXFMbpyXOTB1cfln65qZMKhprEdEXFV67akuYGV8927K6oS+gZwU+7uKFI11OdLfP2DgY8w89T3UN2U9zMkrRARfwXI1Z+lf2YaOKXN/JJaPYSqqC7cpsTX6ih/4VfdPtSulvaiLg1vuE7SGyq++qj8uBjrGlmlJmlaRKxXY7zNSFVC95O+wJYBPlDRiOjXkqo1IE3c+WjZMeok6e2k6T3uJf3tliUNVqtk/Z26qPplrG+MiHUlnRIR7yvrdWchfqXtRTlGbcMbJN0BrEgar1LZ1UfVx8VY19SEcxg1ju3I/xh7RMTd+f7KpB41pSc9SUvRv8Y7UP5UH5KuJY21uIbU8eLZMl+/Q7x5SDNhQ7o6rPvMvVQqLGMdEStLWpK0pHBp0x9Juh34OvBVBnYpB3p/7R0YkFQPBOZrDW+IaqaC6ThOJSJKu4Kr47gY65papVbHNBVFc7WSDUBE/Dn3viqVpG+RpqyYTv8EjUFaj71M7yOdWe4MHKU0W+81EVF6f35JHwN+EXnuL0mLSNo3In5cdqwa1bGM9f6kbv8LM/MYklLHj3RRXcMb+hKL0lQ9VU0RVNdS9GNWIxNOF8Z4TMu9rU7N9/ekmrE5O5LOjiq9AoiI+yT9mzQb9UvA5sBqFYX7cET8qBD7SUkfBno54dSxjPW1wLWSpkbECWW//hhR51Ln25PaLpck1Y4sSxpnt0aJYepain7MmqPbBaiCpPkl/U/uhoiklSRV2eNlf+AO0jQtn8i3D6ggzr2kLsSVkvRXUsPw4qSVP9essAfPBKl//Zbc1XvuimLVZYqkY4GFc/K8lLQaZxVOkfQJSWflnwOruLruhoi4Kg8tODrfv7fCsXRfJY0r+nM+YX07cH3JMeo8LsakprbhnEHqT//+iFhT0vzAdRXV/U4gze+0atmv3SHW2cBawGUMbJsq9Z9QadnijUidH+4itedc3epJVnKso0hnk8fmTfsBD0bEp8uOVSdVuOR4W5zKxzG19fCbSRUDgnPcOpc6nxoRk3OX/HVyz7jSlzqv67gYq5qacFoHT9+I8ioOnkK884ADo+LlWyV9oNP2qGhhLEkLAPuQxjQtHRGl158rreeyH+mMEuAS4PiIqHypgibodFxXdaxL+irwCGnlSJGqjl8bEYeWHSvHq3Op80tJVdbfAF5NqlZbPyLeWnas8ayRbTjAS5LmI5+VSVqBaue0WgSYLukG4PnWxrJnGqgqsbST9B3SFc4CwHXAoaQea6XLsyYck38aQRUvOd6mlnFM2fZtieyYfEVQScKBWpc634G0LtKnSIl0IaDUyVZrPi7GpKYmnMNIq90tI+kXwIakM/WqfLnC1+4jaSXSGdjqFHrSRMnLE5DWUzkyIv5R8uv20czTlhRFVVejNalryXFIPTGvkDRgHFNFsZ6XtCdpQsggzdP1/NBPGZXaljonrYx5ah6VX9WJXZ3HxZjUyCo1AKWldt9M+ie8PiqYRl1phcX9SQPGbgNOiIiXy45TiHctaZbj75G6wu4DzFFVlUaVBhn30Bo0+4WI2LbmIpVGNS05XohXyzgmScuRlh7fkJRwfk+aFPf+iuLVudT510izLN8I/IzUvlLql2Pdx8VY1MiEI+myaJukrtO2EuKcQZpN+RrStBV/i4iDhn7WqOJNi4j1JN0WEW8obqsqZh0krUNaDncX0kjvsyPih90t1axT/yJemwJLUPGS41au3FvyHaQTucnAFNJJ5Kg6y/i46NeoKrV8xTE/8GqlGVJblb+TgKUqCLl64Yv/BOCGCmIU/Sc3sv9F0seBh0ntLD1HnVcmVERs3tWCjU5xAGZlS47XTTUtNNghbp1LnZPHyDwKPEpaf2cR4CxJl0TEZ0fx0o08LmZHoxIOqbfTJ0mDt6bRn3CeAao4Y+6boDMiXm5r3KzCQaSE+gnSuIHN6Z9VYdTUv+xzRyVPDTSmVyacHVHPIl7dUPtCg9l5pGPkUiqchBf6hgK8n3TyczzwmYj4b+sED5jthNPg42KWNbVK7cCIOLqGODPobzQVMB/pDKaS3ieS1o1qlghovf599C/7/DrgyXx7YeCBMmdwkLQjqc58Q1IHj9NJ3aHrniWidLmn2A9IbYhB6oTxyahgkkZJ55DGqlyYe/w1hiqaN22QWIcDP+s0d5qk1cpo6K/zuBirGplwAHLvluUYeCl+ctcKVAKlZQmWAM4CzoiI2yuK81PSdCIX5PvbADtGxH4VxBqTKxOOhqTrgR8Bp+VN7yWN09qgglhbkNoc3kxaluPEKMzrV1KMWhcaLMT9GmnAdmVLnRdivZk0gPvZfH8SsFpE/LHEGLUdF2NVIxOOpFOAFUjL4LYuxaPCaTFqI2kJYFfSJJ6TSInnayXH6OuUMNS2smkMrUw4GpJujbZp7asceJxffyFS0v4S8CBpypRTo4R1mZSWIhhUFNaFKpPqXer8JmDdVs+0XJU2NUpcGbYbx8VY09SEcyepQb95by6T9AZSvfJuEVHq3GOSLibVnRcnI90kIrYqM05TKc3q/ST941V2IzVAHwXlL5ORhwDsRZrW5u/AL0gDd98QEZuVGaupOlXfdUoQo4xR63ExFjU14ZwJfCL6Vw5sBEmrkQ7SnYF/kXp2nR0R/yw5zqKk8T6b0L/8wRHj4R+iDLktbDBR5kBdSb8ijcE5Bfh58ZhvTfFUYqy6Bh634nW6uniaNPyg1PFuuS3sSvpnvPgosHlE7FhijNqOi7GqqQnnCmBtUjflYn/3Suqa6yLpD6SzozMj4u81xJsYEVWOJLdRkrRtexuHKlp+uu6Bx7nNY13SoGqANwC3k6adOaDMdj6ldXD+j/5l1C8lNeiXejI33jU14XSsc66qrrlpcoeL46lhll4bHeVVMYfbVlKsWgce56uOL0fE9Hx/ddL8Zp8FzqmrB5uVp2njcIDmJpYaqzS+B2wFnJ9f/xZJm5Qcw0Yhdx5ZCpgvz9RQHOQ8f0Vh6x54vHIr2QBExB2SVo2Ie8se8yZpadK6O62pZ64hTaPzUKmBxrlGJRxJ10bERpp5/Y6mzMp6Iv1VGpuTqzSqCBT1zdJrs2crYG9gaeC7he3PAl+sKGb7wOO3UeLA4w6mSzqGVI0Mqf3yjjx33Kh737U5EfglqZckpE4YJwJblhxnXGtklVpT1VWlIeks0pfYD4ENSF80kyPivWXGaZpBGrn7VDFoV9LOEXF22a87FigtMfJRUo87SJOF/pi0jMD8EfFcibE69VIrZeBpN46LsapRVzjjQF1VGvuTRkQvlWP8jvSPb0P7zhD7gv4G6VGTtFdEnAosJ+ngmYJFfLfD02Y31vlD7a+qM05EvEj6m3b6u5aWbOt24GcAABFPSURBVLJ/SdqL/kGZu5N6gpahVf55SZOC3kKqdXkjabqgt5QUZ8xzwuktdVVprBIRexY3SNqQdIZpg6h54tGJ+Xcdk7e+hTSY9DTgj/S3F1Wq5m7YHyS14XyPdHJwHSWtK9Q6LnIniHUj4rZ8f03S2l3jhqvUbCZ19nxqqvxl0v5F2ZNTK0maQGrL2J10Vv5b4LRig35FcRuz/hOApOkRscZw25qscVc4+Z/j0prPNitV11xWkt4CvBVYrK2aZhIwoYwY44GkrwCbkRLOBaS1kq4lzRNXdqzKp/CPiBmkCVYvyg32uwNXSjo8ql23aL6IuEyS8qSah0maRgVLWtfxdwRulXQ8A2fwuLXE1x/zGpdwImKGpFckLRQRT3e7PCX5dk1x5iZV0cwJLFjY/gzwnprK0ATvAdYCboqIfSQtTv+XTNlqmcI/J5p3kpLNcqRBkr+qKl5WZzfsOv6O+wAHkKrGIc3gcczgD2+eRlapSToPWAe4hMKa6706eaek10XEAzXGWzY6TNNuIyPphoh4Uz4b35zUVfnOiFi1gliVT+Ev6WRgTdLV2ulR0SzlHeKuT1qLZ2FSm+VCwJERcX0FsWpbCmE8a2rC6diQHhEn1V2WMhTbTySdHRE7VxzvCjqv7FhaL6smk/Rj0liY9wKfJvWoujkqWIhLNUzhL+kV+k/cmji+rdK/o6QpEbGrpNvo/H9V2gShY10jEw6ApLmBlfPdu8uYpr1bJN0UEeu0364wXnFcz7ykyUJfjtEtszsuSVoOmBQRldTV1zmFf13q7IZdGCQuKvo7SnptRDwiadlO+8dTbULj2nAAJG0GnATcTzpwlpH0gYi4upvlGoUY5HY1wSKmtW36vaQbqo7bFJIui7yeT0Tc376tTBGx4PCP6jm1dcOu4+/XmsE7Iv6W2/PWz7tuGG+TgzYy4ZAGWr0j8sqHklYmHbyVTDJYg7UkPUP6x5sv34aKzmbz8gQtc5D+bguVGaOJJM1LGif1aqXF5Irzmy1VcqxVI+KuwUax9/jo9SXo74a9BzV0w+50QlD2SYKkXUlr31xJOjaOlvSZiDirrBhjXVMTzlxRWGY3Iv4saa5uFmg0IqLuLsnT6K9meBm4D9i35jL0ov2ATwJLAsUv/GdI0wSV6dOkbrydRuGXOqtB3ershp1PEiZSw0kCaTXW9VtXNbkr9qWkJePHhUa24Uj6GfAKA/u7Tyi5T71ZR5IOjIiju12OXtahG/b5wM8i4uGS4xxE/0nCw/QnnGeAn5aZ4NS2THvu8n1LVLx0+1jS1IQzD/Ax+if9uwb4cVSwKFWTSNppqP0RcU5dZellucPK/qQVUyFVoRxbZseVJn9W3eiGXcdJgqSjSDM1tOZr2w24NSI+V2XcsaSRCcdmj6QTh9gdvkIcmTyafC5SxxWA9wEzIuJDJcZo7GfVrW7YSgsPLsfAmQZKnR1C0s4U1tyJiKoHz44pjUo4g/VzbxlP/d2tfpLmjIiXJd0SEWu17Ztpm40dkk4BVgBupn+mgejVweJjVdM6Dbyr2wXoZa0p7ztNdw/lTnnfUDcA6wIzJK0QEX8FkPR6qp125p3AGgycKPSIquI11GRg9ajwDDxXg34LeA3paq3nx0zNqkYlnOIAqvHe3302taa8b+LYjjq0GpwPAa6QdG++vxwlTXU/U0DpJ6Su2JsDx5PmcfOYqVl3O6k79iMVxjgS2C4i7qwwxpjWqCq1lg793TcGxlV/d6ufpIfoX+55Pvpn2J4BvFjFFaKkWyPijYXfCwAXRsTGZcdqsjyd09qkZN3XuajkWQ1+HxEbDv/I5mrUFU7BuO/vPjsk/d9Q+12fPawJpNmM20fGt8++XaYX8+8XJC1JWqXytRXFarLDaogxVdIZwLkMTGo926NwVjU14czRVoX2L9KIeRtaa0qbDUlruZyR7+8C3NGVEvWWR7rQdvIbSQuTruhvJHWaOb7mMvS8iLiqhjCTgBeAdxRDA+Mm4TS1Sq1Tf/fbPPnkyEi6HtgoIl7O9+cideF8c3dLNrbVMbHqMPHnAeZt0DpQtZH0ZtIS06uR1oWaADw/nhr069DIK5yI+EzuEdIa+HnceOvvPkqLkM7Gnsj3F8jbbGilT845HEkfA34REU9FxH8kzS/poxHx47rL0uN+SFpO4kxSj7X30z/bfCnyNDr7MnOPwp4dMzWrGlXNJGlFSRtCqheNiIMj4mDgMUkrdLl4veSbwE2Sfi7pJFJVzde7XKYxLyKeGP5RpftwRDxVKMOTpDnWbBZFxD2kKbBmRMSJwNYlhziF1BNuK+AqYGnS4nzjRqMSDvB90hxI7Z7O+2wE8j/bBqQlhM8B3hI9unjdODBBUl8nBUkTSFVCNmteyFMS3SzpSEmfovzvxxUj4sukqrqTSHPFbVByjDGtaVVqi0fEbe0bI+K2vBCWjVBEPEpa593GtouAMyQdm+/vl7fZrHkfKcF8HPgUsAxp4cEytebSe0rSmsCjpEGg40ajOg1I+ktErDTIvnsiYsW6y2RWpTzj8H70tx9dAhyfp/i3WVD1KsGSPgScTerQdCKpbfTLEXHskE9skKYlnNOAyyPip23bPwRsGRG7dadkvUHS8hFxX7fLYVa3TqsEA6WuEixpwng/EWhawlmc1O7wEv1jSiaT6rTfnauJbBCSpkXEelUth2zl8US15ZI0DdijfZXgiChtlWBJD5CrQEknxs358h2hRiWcFkmbk9bTAJgeEZd3szy9QtJNpG6hBwDfa9/vyTvHDknLDrW/OK+gDa81NdBw20YZY37SBMPvJS3b/mvSej/XlhVjrGtkwrHZI2kVYEfSCog/ad8fEYfXXiibJZI2AnaPiI91uyy9JK8vNIOaVgnOy1n/ANizC0vId40Tjs1E0jYRcWG3y2EjI2kdYA/SFET3Aed4ietZU9cqwZI2Jc18sjUwFTgjIs4uM8ZY5oRjM5G0EPAV+pdIvgo4wlOmjB25jWH3/PM4qV3gkIgYsqrNZpbHLk2PiFUrjnM/cBMwBTg/Ip4f+hnN44RjM5F0Nml9kOISyWtFxE7dK5UV5WWYrwH2zSPkkXRvRLy+uyXrTZLOAw6MiAcqjDEpIjoNTB83mjbw08qxQkQUB70dLunmrpXGOtmJ1Ph8haSLgNOZeVkEG7lFgOmSbgD6rjzKXA8HeCnPfTdu51JzwrFOXpS0Uav3TJ6f7sVhnmM1iohzgXMlTQR2IHX0eI2kY4BfRcTvulrA3vPlGmKcAtxFmkvtCFLHhHG1+qer1GwmktYCTgYWypueJA2Cu7V7pbLh5J5PuwC7eRzVyOQZnPcHVgRuA05oLctRQaybImKdwuqs427ZDyccG5SkSQDjvd7ZmiuvwPlfUnvYNsDfIuKgimLdEBFvknQ18FHSXGo3jKd2N1ep2aCcaGwcWD0i3gAg6QTghgpjHZevQr8MnE+aS+3QCuONOb7CMbNxS9KNEbHuYPetXE44ZjZuSZpBf680AfMBL+TbUcYS05IOHmr/eJoyylVqNihJywPrAHdExF3dLo9Z2WqaVmbBGmL0BCcc6yPp3IjYMd/egbRK6pXANyR9IyJ+3sXimfWq+SPic5J2iYgzu12YbnKVmvVpddvMt68jTSx4n6RXA5dFxFrdLaFZ78lLSbwRmDbe24d8hWNFxbOPOVuLsUXE43kqFTObdReRxrItIKnY87O0dqJe4Ssc61NoQBUwD7BsRDySl96d6kW9zGafpPMiYodul6ObnHBsWJIWBlaLiD90uyxm1ruccMzMaiBpJ+BbwGtItQiuUjPrRNJtrRHZZjbrJN0DbBcR42rCziJ3GrA++Qys4y5giTrLYtZA/xjPyQaccGygM4BfMLC3Wsu8HbaZ2chNzZOFngv0LV0dEed0r0j1csKxoluBb0fE7e07JG3RhfKYNckk0rQ57yhsC2DcJBy34VgfSRuTpmefaZldSZMjYmoXimVmDeGEY2ZWA0lLA0cDG+ZN1wAHRcRD3StVvebodgFs7JA0v6TPSvqMpHkl7S3pfElHSlqg2+Uz63EnktbBWTL//DpvGzd8hWN9JE0BHiRN0b4Kab31M4DtgSUi4n1dLJ5ZT5N0c0SsPdy2JnOnAStaOSJ2lSTgEWCLiAhJ1wK3dLlsZr3uX5L2Ak7L93cH/tXF8tTOVWo2k0iXvRfk3637vhQ2G50PArsCj5JO6N4D7NPVEtXMVzhWNFXSAhHxXER8sLVR0grAs10sl1nPi4i/kaqnxy234diISFL4YDGbZZIOHWJ3RMRXaytMlznh2ACSXgXsAayaN90JnBYR46qu2awskj7dYfNEYF/gVRExbnqAOuFYH0mrAZcDFwM3keZQWwfYEnhbRNzVxeKZ9TxJCwIHkZLNFOA7EfHP7paqPk441kfSWcCUiJjStn1nYI+I2Lk7JTPrbZIWBQ4G9gROAn4QEU92t1T1c8KxPpLujohVZnWfmQ1O0lHATsBxwI8i4rkuF6lrnHCsj6QbI2LdWd1nZoOT9AppduiXGTi8YNwtwOZu0Vb0GkkHd9guYLG6C2PWBBHh8Y6ZE44V/RRYcJB9x9dZEDNrHlepmZlZLXypZwNI2kbS1ZIezz9XSdq22+Uys97nKjXrI+nDwH7AZ4HWYmuTgW9KWjoijuta4cys57lKzfpIugPYKCKeaNv+KuDaiFitOyUzsyZwlZoVqT3ZAHhaGzMrgxOOFT0jaa32jXmbZ4s2s1FxG44VfRo4X9KJwLS8bTLwAWCvrpXKzBrBbTg2gKTFgY8Ba+RNd5Cm43i0e6UysyZwwrE+ko4DLgQujQhXoZlZqZxwrI+kDYBtgLcDLwG/Ay6KiFu6WjAzawQnHOsod4V+BykBvRG4kZR8pgz5RDOzQTjh2IhIWg/YOiL+t9tlMbPe5IRjA0jaCtgRWCpvehg4NyIu7l6pzKwJnHCsj6TvAysDJwMP5c1LA+8H/hIRB3WrbGbW+5xwrI+kP0fEyh22C/hzRKzUhWKZWUN4pgEr+rek9TtsXx/4d92FMbNm8UwDVrQ3cIykBemvUlsGeDrvMzObba5Ss5lIWoJCpwHPMmBmZXCVmg0gaRNgoYiYBswL7OUF2MysDL7CsT65l9qbSFWtF5NmHLgQ2BS4KSI+08XimVmPc8KxPpKmA2sC85HG3ywVES9ImouUcNbsagHNrKe5Ss2KItIZyCut+/n3K/hYMbNRci81K/qtpGtIbTfHA1MkXU+qUru6qyUzs57nKjUbQNJbSFc610taAXg38ABwVkS8MvSzzcwG54RjZma1cL289ZG0jKTTJV0j6Yu5s0Br37ndLJuZ9T4nHCv6GXAlcCDwWuCqvC4OwLLdKpSZNYM7DVjRYhHxk3z7QEl7AVdL2p7+HmtmZrPFCceK5pI0b0T8GyAiTpX0KGkQ6MTuFs3Mep2r1KzoeGCD4oaIuBTYBbi9KyUys8ZwLzUzM6uFr3BsAEmbSzpH0vT8c5akzbpdLjPrfU441kfSO0k91X4N7AHsCVwA/MwzRpvZaLlKzfpIuhI4KCJuadv+RuDoiNi0KwUzs0bwFY4VLdGebAAi4lZg8S6Ux8waxAnHip6fzX1mZsPyOBwrWkHS+R22C3h93YUxs2ZxG471kTRkG01EXFVXWcyseZxwbCaS5gVWzHfvac08YGY2Gm7DsT6S5pR0JPAQcBJwMvCgpCOLM0ebmc0OJxwrOgpYFFg+ItaLiHWBFYCFgW93tWRm1vNcpWZ9JP0FWDnaDgpJE4C7ImKl7pTMzJrAVzhWFO3JJm+cgZcnMLNRcsKxojskvb99Y14X564ulMfMGsRVatZH0lLAOcCLwLS8eTIwH/DuiHi4W2Uzs97nhGMzkfQ2YI18946IuKyb5TGzZnDCMTOzWrgNx8zMauGEY2ZmtXDCMTOzWjjhmJlZLf4f8FrC8EmKq5gAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.title('Relevancia de los descriptores')\n",
        "plt.bar(range(X_train.shape[1]),relevancias[indices],color='lightblue',align='center')\n",
        "plt.xticks(range(X_train.shape[1]),etiquetas_descriptores[indices],rotation=90)\n",
        "plt.xlim([-1,X_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svEAaOXaId5w"
      },
      "source": [
        "Recuerda guardar este notebook usando la opción *\"Save in GitHub...\"*."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "practica6_adicional1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}